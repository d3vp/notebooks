{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np, pandas as pd, os, time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Parallelism** means performing multiple tasks or calculations at the same time e.g. on different CPUs or cores simultaneously.\n",
    "\n",
    "**Concurrency** means ability to execute tasks out-of-order, possibly at the same time. In a concurrent application, two tasks can start, run, and complete in overlapping time periods i.e Task-2 can start even before Task-1 gets completed.\n",
    "\n",
    "How concurrency is achieved various across architectures. In a single core environment, concurrency is achieved via a process called context-switching. If its a multi-core environment, concurrency can be achieved through parallelism."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Synchronous** programming model allows tasks to be created and executed in order: next task is executed only after current task has finished.\n",
    "\n",
    "**Asynchronous** programming model allows task switching: new tasks can be started without waiting for current tasks to finish.\n",
    "- Asynchronous programming model helps to achieve concurrency. In a multi-threaded environment, it allows parallelism.\n",
    "- Can be achieved via context switching in OS threads, or cooperative multitasking in user space."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Sync.png\" width=\"80%\"> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Async.png\" width=\"80%\"> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To summarize:\n",
    "- Single Threaded and Multi-Threaded -> The environment of task execution. CPUs, cores, etc.\n",
    "- Concurrency and Parallelism -> The way tasks are executed in the environment. \n",
    "- Synchronous and Asynchronous -> Programming model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above introduction is derived from this nice article: https://medium.com/swift-india/concurrency-parallelism-threads-processes-async-and-sync-related-39fd951bc61d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1 What python offers?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Parallelism across different CPUs using multiprocessing.Process and concurrent.futures.ProcessPoolExecutor\n",
    "- Concurrency, but unfortunately not parallelism, using *threading* module and concurrent.futures.ThreadPoolExecutor. \n",
    "    - Threads in general allow parallelism but not in python due to Global Interpreter Lock (GIL).\n",
    "- Asynchronous programming (cooperative multitasking) using asyncio library."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Multiprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two main libraries for multiprocessing: \n",
    "- concurrent.futures, which provides high-level API and is easier to use\n",
    "- multiprocessing, which gives more flexilibity at the expense of more boilerplate code\n",
    "\n",
    "Below I give two small examples using each of the libraries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 Using concurrent.futures\n",
    "- Provides ProcessPoolExecutor and ThreadPoolExecutor classes\n",
    "    - Allows creating a pool of processes or threads. Distributing tasks to the pool and managing processes in the pool is take care of by library.\n",
    "    \n",
    "- There are two ways to assign tasks to and gather results from the processes in the pool.\n",
    "    - Executor.map function\n",
    "    - Executor.submit function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Executor.map(func, *iterables, timeout=None, chunksize=1)**\n",
    "- Similar to map(func, *iterables)\n",
    "- For each value in the iterables, the callable func is executed on different processes in the pool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 4, 9, 16, 25]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = map(lambda x: x**2, [1,2,3,4,5])\n",
    "list(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import ProcessPoolExecutor\n",
    "\n",
    "# Since processes are forked, any global data will be available to each process but it is not shared\n",
    "DIM = 10000\n",
    "\n",
    "def worker(vector):\n",
    "    time.sleep(0.01) ## Comment this line and run\n",
    "    return np.linalg.norm(vector)\n",
    "\n",
    "def parallel():\n",
    "    vectors = [np.random.rand(DIM) for i in range(1000)]\n",
    "    with ProcessPoolExecutor(max_workers=4) as executor:  # usually more workers than CPUs is not good idea\n",
    "        result_iter = executor.map(worker, vectors) \n",
    "        result = sum(result_iter)\n",
    "        print(f'Sum of Norms: {result}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at how fast it is compared to sequential approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum of Norms: 57738.268572516885\n",
      "Sum of Norms: 57733.0925081861\n",
      "Sum of Norms: 57720.342560219\n",
      "Sum of Norms: 57719.221496151535\n",
      "Sum of Norms: 57730.91516878594\n",
      "3.11 s ± 33.8 ms per loop (mean ± std. dev. of 5 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 1 -r 5\n",
    "parallel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sequential():\n",
    "    vectors = [np.random.rand(DIM) for i in range(1000)]\n",
    "    result = sum(worker(v) for v in vectors)\n",
    "    print(f'Sum of Norms: {result}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum of Norms: 57745.07947708336\n",
      "Sum of Norms: 57728.51933057455\n",
      "Sum of Norms: 57737.54008351761\n",
      "Sum of Norms: 57739.985365237895\n",
      "Sum of Norms: 57746.92520893234\n",
      "11.7 s ± 173 ms per loop (mean ± std. dev. of 5 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 1 -r 5\n",
    "sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remarks:\n",
    "- Parallelism is best achieved when execution time per process >> communication time between processes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Executor.submit(func, *args, **kwargs)**\n",
    "- Schedules the callable, fn, to be executed as fn(*args **kwargs) and returns a Future object representing the execution of the callable.\n",
    "- A Future object encapsulates the asynchronous execution of a callable: results as well as exceptions are wrapped into the object.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import as_completed\n",
    "\n",
    "# an example to show how exception are be captured and sent to another process\n",
    "def worker(inp):\n",
    "    if np.random.random() < 0.3:\n",
    "        raise Exception('Bad luck!')\n",
    "    return {'pid': os.getpid(), 'result': inp*inp}\n",
    "\n",
    "def master():\n",
    "    with ProcessPoolExecutor(max_workers=4) as executor:\n",
    "        futures = {executor.submit(worker, i) for i in range(10)}\n",
    "        \n",
    "        while len(futures) > 0:\n",
    "            completed_futures = [f for f in futures if f.done()]\n",
    "            for future in completed_futures:\n",
    "                exception = future.exception()\n",
    "                if exception is None:\n",
    "                    print('Result: %s' % future.result())\n",
    "                else:\n",
    "                    print('Exception: %s' % exception)\n",
    "                futures.remove(future)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: {'pid': 39487, 'result': 0}\n",
      "Result: {'pid': 39490, 'result': 9}\n",
      "Exception: Bad luck!\n",
      "Exception: Bad luck!\n",
      "Exception: Bad luck!\n",
      "Result: {'pid': 39488, 'result': 1}\n",
      "Result: {'pid': 39487, 'result': 64}\n",
      "Result: {'pid': 39489, 'result': 4}\n",
      "Result: {'pid': 39488, 'result': 81}\n",
      "Exception: Bad luck!\n"
     ]
    }
   ],
   "source": [
    "master()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following is an easier way to do the same thing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import as_completed\n",
    "\n",
    "def worker(inp):\n",
    "    if np.random.random() < 0.3:\n",
    "        raise Exception('Bad luck!')\n",
    "    return {'pid': os.getpid(), 'result': inp*inp}\n",
    "\n",
    "def master():\n",
    "    with ProcessPoolExecutor(max_workers=4) as executor:\n",
    "        futures = [executor.submit(worker, i) for i in range(10)]\n",
    "        for future in as_completed(futures):\n",
    "            exception = future.exception()\n",
    "            if exception is None:\n",
    "                print('Result: %s' % future.result())\n",
    "            else:\n",
    "                print('Exception: %s' % exception)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: {'pid': 39398, 'result': 0}\n",
      "Result: {'pid': 39400, 'result': 4}\n",
      "Result: {'pid': 39401, 'result': 9}\n",
      "Result: {'pid': 39399, 'result': 1}\n",
      "Exception: Bad luck!\n",
      "Result: {'pid': 39400, 'result': 64}\n",
      "Result: {'pid': 39400, 'result': 81}\n",
      "Exception: Bad luck!\n",
      "Exception: Bad luck!\n",
      "Exception: Bad luck!\n"
     ]
    }
   ],
   "source": [
    "master()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remarks:\n",
    "- There are some more useful methods on Future object: add_done_callback\n",
    "- *timeout* argument to result and exception methods is also very useful"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3 Using multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Queue, Process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.4 Pure python vs zeromq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An excellent guide to zeromq, which is a lightweight networking library and concurrency framework.\n",
    "- http://zguide.zeromq.org/page:all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To install zeromq and python bindings:\n",
    "- conda install zeromq pyzmq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Asynchronous Programming using asyncio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.0 An example of undesirable context-switching when using Threading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00000000000000000000000000000000000000000000000000\n",
      "11111111111111111111111111111111111111111111111111\n",
      "00000000000000000000000000000000000000000000000000\n",
      "11111111111111111111111111111111111111111111111111\n",
      "0000000000000000000000000000000000000000000000000011111111111111111111111111111111111111111111111111\n",
      "\n",
      "1111111111111111111111111111111111111111111111111100000000000000000000000000000000000000000000000000\n",
      "\n",
      "11111111111111111111111111111111111111111111111111\n",
      "00000000000000000000000000000000000000000000000000\n",
      "11111111111111111111111111111111111111111111111111\n",
      "00000000000000000000000000000000000000000000000000\n",
      "11111111111111111111111111111111111111111111111111\n",
      "00000000000000000000000000000000000000000000000000\n",
      "11111111111111111111111111111111111111111111111111\n",
      "00000000000000000000000000000000000000000000000000\n",
      "11111111111111111111111111111111111111111111111111\n",
      "00000000000000000000000000000000000000000000000000\n",
      "11111111111111111111111111111111111111111111111111\n",
      "00000000000000000000000000000000000000000000000000\n"
     ]
    }
   ],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "def print_func(s):\n",
    "    for i in range(10):\n",
    "        print(s)\n",
    "        time.sleep(0.1)\n",
    "\n",
    "    \n",
    "with ThreadPoolExecutor(max_workers=3) as executor:  # change num of workers\n",
    "    executor.submit(print_func, '0'*50)\n",
    "    executor.submit(print_func, '1'*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1 Generators\n",
    "Generators are functions that generates values. A function usually returns a value and then the underlying scope is destroyed. When we call again, the function is started from scratch. It’s one time execution. But a generator function can yield a value and pause the execution of the function. The control is returned to the calling scope."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_squares(max_value=None):\n",
    "    n = 0\n",
    "    while True:\n",
    "        yield n * n\n",
    "        n += 1\n",
    "        if n*n > max_value:\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A generator function doesn’t directly return any values but when we call it, we get a generator object which is like an iterable. So we can call next() on a generator object to iterate over the values. Or run a for loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "squares = gen_squares()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(squares)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "squares_upto_100 = gen_squares(max_value=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(squares_upto_100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "4\n",
      "9\n",
      "16\n",
      "25\n",
      "36\n",
      "49\n",
      "64\n",
      "81\n",
      "100\n",
      "121\n",
      "144\n",
      "169\n",
      "196\n"
     ]
    }
   ],
   "source": [
    "for s in gen_squares(max_value=200):\n",
    "    print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 Naive task switching using generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00000000000000000000000000000000000000000000000000\n",
      "11111111111111111111111111111111111111111111111111\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "00000000000000000000000000000000000000000000000000\n",
      "11111111111111111111111111111111111111111111111111\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "00000000000000000000000000000000000000000000000000\n",
      "11111111111111111111111111111111111111111111111111\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "00000000000000000000000000000000000000000000000000\n",
      "11111111111111111111111111111111111111111111111111\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "00000000000000000000000000000000000000000000000000\n",
      "11111111111111111111111111111111111111111111111111\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "00000000000000000000000000000000000000000000000000\n",
      "11111111111111111111111111111111111111111111111111\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "00000000000000000000000000000000000000000000000000\n",
      "11111111111111111111111111111111111111111111111111\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "00000000000000000000000000000000000000000000000000\n",
      "11111111111111111111111111111111111111111111111111\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "00000000000000000000000000000000000000000000000000\n",
      "11111111111111111111111111111111111111111111111111\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "00000000000000000000000000000000000000000000000000\n",
      "11111111111111111111111111111111111111111111111111\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n"
     ]
    }
   ],
   "source": [
    "from itertools import cycle\n",
    "\n",
    "def print_func(s):\n",
    "    for i in range(10):\n",
    "        print(s)\n",
    "        time.sleep(np.random.random())\n",
    "        yield None\n",
    "        \n",
    "def print_func2():\n",
    "    for i in range(20):\n",
    "        print('+'*50)\n",
    "        time.sleep(np.random.random())\n",
    "        yield None\n",
    "\n",
    "def loop(generators):\n",
    "    for gen in cycle(generators): # [A, B ,C] -> A, B, C, A, B, C, ...\n",
    "        try:\n",
    "            value = next(gen)  # we don't care about value that is yielded\n",
    "        except StopIteration:\n",
    "            break\n",
    "\n",
    "loop([print_func('0'*50), \n",
    "      print_func('1'*50), \n",
    "      print_func2()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3 Async programming using Coroutines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Event Loop\n",
    "- Coroutines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Revisiting the context-switching example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Task pending coro=<print_func() running at <ipython-input-18-1e6a37addcb3>:3>>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00000000000000000000000000000000000000000000000000\n",
      "11111111111111111111111111111111111111111111111111\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "11111111111111111111111111111111111111111111111111\n",
      "11111111111111111111111111111111111111111111111111\n",
      "00000000000000000000000000000000000000000000000000\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "11111111111111111111111111111111111111111111111111\n",
      "00000000000000000000000000000000000000000000000000\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "11111111111111111111111111111111111111111111111111\n",
      "00000000000000000000000000000000000000000000000000\n",
      "00000000000000000000000000000000000000000000000000\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "11111111111111111111111111111111111111111111111111\n",
      "11111111111111111111111111111111111111111111111111\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "00000000000000000000000000000000000000000000000000\n",
      "11111111111111111111111111111111111111111111111111\n",
      "00000000000000000000000000000000000000000000000000\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "11111111111111111111111111111111111111111111111111\n",
      "00000000000000000000000000000000000000000000000000\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "11111111111111111111111111111111111111111111111111\n",
      "00000000000000000000000000000000000000000000000000\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "00000000000000000000000000000000000000000000000000\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "\n",
    "async def print_func(s):\n",
    "    for i in range(10):\n",
    "        print(s)\n",
    "        await asyncio.sleep(np.random.random())\n",
    "    \n",
    "asyncio.ensure_future(print_func('0'*50))\n",
    "asyncio.ensure_future(print_func('1'*50))\n",
    "asyncio.ensure_future(print_func('+'*50))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.5 Small example: Fetching webpages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "URLS = ['https://facebook.com',\n",
    "                'https://github.com',\n",
    "                'https://google.com',\n",
    "                'https://microsoft.com',\n",
    "                'https://yahoo.com']\n",
    "\n",
    "def sequential(urls):\n",
    "    start = time.time()\n",
    "    for url in urls:\n",
    "        r = requests.get(url)\n",
    "    print('Elapse time: %s' % (time.time()-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapse time: 10.780002117156982\n"
     ]
    }
   ],
   "source": [
    "sequential(URLS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "from aiohttp import ClientSession\n",
    "\n",
    "async def fetch(url, session):\n",
    "    async with session.get(url) as response:\n",
    "        resp = await response.read()\n",
    "        return resp\n",
    "    \n",
    "async def fetch_all(urls):\n",
    "    tasks = []\n",
    "    start = time.time()\n",
    "    async with ClientSession() as session:\n",
    "        for url in urls:\n",
    "            task = asyncio.ensure_future(fetch(url, session))\n",
    "            tasks.append(task) \n",
    "        await asyncio.gather(*tasks) \n",
    "    print('Elapse time: %s' % (time.time()-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "This event loop is already running",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-d8120420bcf5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mfuture\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0masyncio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_future\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetch_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mURLS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# not blocking\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mloop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0masyncio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_event_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mloop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_until_complete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfuture\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# blocking\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/Cellar/python/3.7.1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/asyncio/base_events.py\u001b[0m in \u001b[0;36mrun_until_complete\u001b[0;34m(self, future)\u001b[0m\n\u001b[1;32m    558\u001b[0m         \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_done_callback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_run_until_complete_cb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_forever\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mnew_task\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcancelled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python/3.7.1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/asyncio/base_events.py\u001b[0m in \u001b[0;36mrun_forever\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    513\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    514\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_running\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 515\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'This event loop is already running'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    516\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_running_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    517\u001b[0m             raise RuntimeError(\n",
      "\u001b[0;31mRuntimeError\u001b[0m: This event loop is already running"
     ]
    }
   ],
   "source": [
    "future = asyncio.ensure_future(fetch_all(URLS)) # not blocking\n",
    "loop = asyncio.get_event_loop()\n",
    "loop.run_until_complete(future) # blocking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapse time: 1.7943570613861084\n"
     ]
    }
   ],
   "source": [
    "asyncio.ensure_future(fetch_all(URLS))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Cool JupyterLab Trick"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
