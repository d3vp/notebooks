{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np, pandas as pd, os, time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Parallelism** means performing multiple tasks or calculations at the same time e.g. on different CPUs or cores simultaneously.\n",
    "\n",
    "**Concurrency** means ability to execute tasks out-of-order, possibly at the same time. In a concurrent application, two tasks can start, run, and complete in overlapping time periods i.e Task-2 can start even before Task-1 gets completed.\n",
    "\n",
    "How concurrency is achieved various across architectures. In a single core environment, concurrency is achieved via a process called context-switching. If its a multi-core environment, concurrency can be achieved through parallelism."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Synchronous** programming model allows tasks to be created and executed in order: next task is executed only after current task has finished.\n",
    "\n",
    "**Asynchronous** programming model allows task switching: new tasks can be started without waiting for current tasks to finish.\n",
    "- Asynchronous programming model helps to achieve concurrency. In a multi-threaded environment, it allows parallelism.\n",
    "- Can be achieved via context switching in OS threads, or cooperative multitasking in user space."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Sync.png\" width=\"80%\"> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Async.png\" width=\"80%\"> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To summarize:\n",
    "- Single Threaded and Multi-Threaded -> The environment of task execution. CPUs, cores, etc.\n",
    "- Concurrency and Parallelism -> The way tasks are executed in the environment. \n",
    "- Synchronous and Asynchronous -> Programming model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above introduction is derived from this nice article: https://medium.com/swift-india/concurrency-parallelism-threads-processes-async-and-sync-related-39fd951bc61d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1 What python offers?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Parallelism across different CPUs using multiprocessing.Process and concurrent.futures.ProcessPoolExecutor\n",
    "- Concurrency, but unfortunately not parallelism, using *threading* module and concurrent.futures.ThreadPoolExecutor. \n",
    "    - Threads in general allow parallelism but not in python due to Global Interpreter Lock (GIL).\n",
    "- Asynchronous programming (cooperative multitasking) using asyncio library.\n",
    "- CPU-intensive vs IO-intensive tasks\n",
    "    - \"asyncio is often a perfect fit for IO-bound and high-level structured network code.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Multiprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two main libraries for multiprocessing: \n",
    "- concurrent.futures, which provides high-level API and is easier to use\n",
    "- multiprocessing, which gives more flexilibity at the expense of more boilerplate code\n",
    "\n",
    "Below I give two small examples using each of the libraries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 Using concurrent.futures\n",
    "- Provides ProcessPoolExecutor and ThreadPoolExecutor classes\n",
    "    - Allows creating a pool of processes or threads. Distributing tasks to the pool and managing processes in the pool is take care of by library.\n",
    "    \n",
    "- There are two ways to assign tasks to and gather results from the processes in the pool.\n",
    "    - Executor.map function\n",
    "    - Executor.submit function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Executor.map(func, *iterables, timeout=None, chunksize=1)**\n",
    "- Similar to map(func, *iterables)\n",
    "- For each value in the iterables, the callable func is executed on different processes in the pool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = map(lambda x: x**2, [1,2,3,4,5])\n",
    "list(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import ProcessPoolExecutor\n",
    "\n",
    "# Since processes are forked, any global data will be available to each process but it is not shared\n",
    "DIM = 10000\n",
    "\n",
    "def worker(vector):\n",
    "    time.sleep(0.01) ## Comment this line and run\n",
    "    return np.linalg.norm(vector)\n",
    "\n",
    "def parallel():\n",
    "    vectors = [np.random.rand(DIM) for i in range(1000)]\n",
    "    with ProcessPoolExecutor(max_workers=4) as executor:  # usually more workers than CPUs is not good idea\n",
    "        result_iter = executor.map(worker, vectors) \n",
    "        result = sum(result_iter)\n",
    "        print(f'Sum of Norms: {result}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at how fast it is compared to sequential approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit -n 1 -r 5\n",
    "parallel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sequential():\n",
    "    vectors = [np.random.rand(DIM) for i in range(1000)]\n",
    "    result = sum(worker(v) for v in vectors)\n",
    "    print(f'Sum of Norms: {result}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit -n 1 -r 5\n",
    "sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remarks:\n",
    "- Parallelism is best achieved when execution time per process >> communication time between processes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Executor.submit(func, *args, **kwargs)**\n",
    "- Schedules the callable, fn, to be executed as fn(*args **kwargs) and returns a Future object representing the execution of the callable.\n",
    "- A Future object encapsulates the asynchronous execution of a callable: results as well as exceptions are wrapped into the object.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import as_completed\n",
    "\n",
    "# an example to show how exception are be captured and sent to another process\n",
    "def worker(inp):\n",
    "    if np.random.random() < 0.3:\n",
    "        raise Exception('Bad luck!')\n",
    "    return {'pid': os.getpid(), 'result': inp*inp}\n",
    "\n",
    "def master():\n",
    "    with ProcessPoolExecutor(max_workers=4) as executor:\n",
    "        futures = {executor.submit(worker, i) for i in range(10)}\n",
    "        \n",
    "        while len(futures) > 0:\n",
    "            completed_futures = [f for f in futures if f.done()]  # we check if future is done or we will be blocked below\n",
    "            for future in completed_futures:\n",
    "                exception = future.exception()   # this method is blocking\n",
    "                if exception is None:\n",
    "                    print('Result: %s' % future.result())   # this method is blocking too\n",
    "                else:\n",
    "                    print('Exception: %s' % exception)\n",
    "                futures.remove(future)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following is an easier way to do the same thing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import as_completed\n",
    "\n",
    "def worker(inp):\n",
    "    if np.random.random() < 0.3:\n",
    "        raise Exception('Bad luck!')\n",
    "    return {'pid': os.getpid(), 'result': inp*inp}\n",
    "\n",
    "def master():\n",
    "    with ProcessPoolExecutor(max_workers=4) as executor:\n",
    "        futures = [executor.submit(worker, i) for i in range(10)]\n",
    "        for future in as_completed(futures):\n",
    "            exception = future.exception()\n",
    "            if exception is None:\n",
    "                print('Result: %s' % future.result())\n",
    "            else:\n",
    "                print('Exception: %s' % exception)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remarks:\n",
    "- There are some more useful methods on Future object: add_done_callback\n",
    "- *timeout* argument to result and exception methods is also very useful"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3 Using multiprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Very simple example is shown below. However, in real applications, much more needs to be done to prevent deadlocks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Process, Queue\n",
    "\n",
    "def worker(qin, qout):\n",
    "    while True:\n",
    "        inp = qin.get()\n",
    "        if inp is None:\n",
    "            break\n",
    "        # too messy to deal with exceptions!\n",
    "        #if np.random.random() < 0.3:\n",
    "        #    raise Exception('Bad luck!')\n",
    "        qout.put({'pid': os.getpid(), 'result': inp*inp})\n",
    "\n",
    "def master():\n",
    "    qin, qout = Queue(), Queue()\n",
    "    procs = [Process(target=worker, args=(qin,qout)) for i in range(4)]\n",
    "    for p in procs:\n",
    "        p.start()\n",
    "    for i in range(10):\n",
    "        qin.put(i)\n",
    "    for i in range(10):\n",
    "        print(qout.get())\n",
    "    for i in range(len(procs)):\n",
    "        qin.put(None)\n",
    "    for p in procs:\n",
    "        p.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remarks:\n",
    "- Notice a lot of boilerplate when using multiprocessing as compared to concurrent.futures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.4 Pure python vs zeromq\n",
    "- Advantages of python standard libraries:\n",
    "    - No external dependencies\n",
    "    - Quick and easy to implement\n",
    "- Cons\n",
    "    - Not robust. If a parent or one of the children processes dies, everything has to be launched again. Compare this to zeromq: when using zeromq, master or worker processes can be stopped and started at any time.\n",
    "    - IO between processes is not as fast as zeromq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An excellent guide to zeromq, which is a lightweight networking library and concurrency framework.\n",
    "- http://zguide.zeromq.org/page:all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Asynchronous Programming using asyncio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.0 An example of undesirable context-switching when using Threading\n",
    "Here we run a function in two threads and both are sharing the common resource, stdout, where they print a line. Ideally, we want each function to print the line fully and not be interrupted in the middle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "def print_func(s):\n",
    "    for i in range(10):\n",
    "        for c in s:\n",
    "            print(c, end='')\n",
    "        print()\n",
    "        time.sleep(0.1)\n",
    "\n",
    "    \n",
    "with ThreadPoolExecutor(max_workers=2) as executor:  # change num of workers to 2\n",
    "    executor.submit(print_func, '0'*50)\n",
    "    executor.submit(print_func, '1'*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1 Generators\n",
    "Generators are functions that generates values. A function usually returns a value and then the underlying scope is destroyed. When we call again, the function is started from scratch. It’s one time execution. But a generator function can yield a value and pause the execution of the function. The control is returned to the calling scope."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_squares(max_value=None):\n",
    "    n = 0\n",
    "    while True:\n",
    "        yield n * n\n",
    "        n += 1\n",
    "        if n*n > max_value:\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A generator function doesn’t directly return any values but when we call it, we get a generator object which is like an iterable. So we can call next() on a generator object to iterate over the values. Or run a for loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "squares = gen_squares()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next(squares)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "squares_upto_100 = gen_squares(max_value=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next(squares_upto_100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for s in gen_squares(max_value=200):\n",
    "    print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 Naive task switching using generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import cycle\n",
    "\n",
    "def print_func(s):\n",
    "    for i in range(10):\n",
    "        for c in s:\n",
    "            print(c, end='')\n",
    "        print()\n",
    "        time.sleep(np.random.random())  # Ideally we want to yield here\n",
    "        yield None # we don't care about values, only computation above!\n",
    "        \n",
    "def print_func2():\n",
    "    s='+'*50\n",
    "    for i in range(10):\n",
    "        for c in s:\n",
    "            print(c, end='')\n",
    "        print()\n",
    "        time.sleep(np.random.random())\n",
    "        yield None\n",
    "\n",
    "def loop(generators):\n",
    "    for gen in cycle(generators): # [A, B ,C] -> A, B, C, A, B, C, ...\n",
    "        try:\n",
    "            value = next(gen)  # we don't care about value that is yielded\n",
    "        except StopIteration:\n",
    "            break\n",
    "\n",
    "loop([print_func('0'*50), \n",
    "      print_func('1'*50), \n",
    "      print_func2()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the many problems with the above naive approach is that tasks are not scheduled optimally. Ideally, we would like to \"yield\" from the generator above when it is waiting (wasting time) during *sleep* function. This is what the coroutines allows us to achieve: we can yield when we need to wait for something, for example, a response for an HTTP request."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3 Async programming using Coroutines and asyncio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Event Loop: The event loop is the core of every asyncio application. Event loops run asynchronous tasks and callbacks, perform network IO operations\n",
    "- Coroutines are declared with async/await syntax. They are like function except that they can only be executed by scheduling them into the event loop. They yield control to the loop using \"await\" statements."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Revisiting the context-switching example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "\n",
    "async def print_func(s):\n",
    "    for i in range(10):\n",
    "        for c in s:\n",
    "            print(c, end='')\n",
    "        print()\n",
    "        await asyncio.sleep(np.random.random())\n",
    "    \n",
    "asyncio.ensure_future(print_func('0'*50))\n",
    "asyncio.ensure_future(print_func('1'*50))\n",
    "asyncio.ensure_future(print_func('+'*50))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.5 Small example: Fetching webpages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "URLS = ['https://facebook.com',\n",
    "                'https://github.com',\n",
    "                'https://google.com',\n",
    "                'https://microsoft.com',\n",
    "                'https://yahoo.com']\n",
    "\n",
    "def sequential(urls):\n",
    "    start = time.time()\n",
    "    for url in urls:\n",
    "        r = requests.get(url)\n",
    "    print('Elapse time: %s' % (time.time()-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequential(URLS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "from aiohttp import ClientSession\n",
    "\n",
    "async def fetch(url, session):\n",
    "    async with session.get(url) as response:\n",
    "        resp = await response.read()\n",
    "        return resp\n",
    "    \n",
    "async def fetch_all(urls):\n",
    "    tasks = []\n",
    "    start = time.time()\n",
    "    async with ClientSession() as session:\n",
    "        for url in urls:\n",
    "            task = asyncio.ensure_future(fetch(url, session))\n",
    "            tasks.append(task) \n",
    "        await asyncio.gather(*tasks) \n",
    "    print('Elapse time: %s' % (time.time()-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "future = asyncio.ensure_future(fetch_all(URLS)) # not blocking\n",
    "loop = asyncio.get_event_loop()\n",
    "loop.run_until_complete(future) # blocking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asyncio.ensure_future(fetch_all(URLS))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Cool JupyterLab Trick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def some_cool_function(data):\n",
    "    data['x'] = 0\n",
    "    while True:\n",
    "        data['x'] += 1\n",
    "        time.sleep(0.5)\n",
    "        print('=+', end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=+=+=+=+=+"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-5cc1a9e49e2b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msome_cool_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-3-8b420b7eb15e>\u001b[0m in \u001b[0;36msome_cool_function\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'x'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'=+'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "data={}\n",
    "some_cool_function(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['x']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def some_cool_function(data):\n",
    "    data['x'] = 0\n",
    "    while True:\n",
    "        data['x'] += 1\n",
    "        await asyncio.sleep(0.5)\n",
    "        #print('=+', end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=+=+=+=+=+=+=+=+=+=+"
     ]
    }
   ],
   "source": [
    "task = asyncio.ensure_future(some_cool_function(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=+=+=+=+=+=+=+=+=+"
     ]
    }
   ],
   "source": [
    "data['x']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=+"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task.cancel()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
